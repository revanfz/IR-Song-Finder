{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tkinter import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengimpor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/revanfz/revanfz/main/dataset_lirik.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Casefolding : mengubah setiap karakter pada lirik menjadi lowercase (huruf non-kapital)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lirik\"] = df[\"lirik\"].replace(r'\\n', ' ', regex=True).str.casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menghilangkan Stopwords\n",
    "```\n",
    "Stopwords adalah kata yang tidak memiliki makna ketika berdiri sendiri\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_stop_factory = stopwords.words('indonesian')\n",
    "en_stop_factory = stopwords.words('english')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi untuk Menghilangkan stopword bahasa indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_word_id(text):\n",
    "    clean_words = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word not in id_stop_factory:\n",
    "            clean_words.append(word)\n",
    "    return ' '.join(clean_words)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi untuk Menghilangkan stopwords bahasa inggris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_word_en(text):\n",
    "    clean_words = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word not in en_stop_factory:\n",
    "            clean_words.append(word)\n",
    "    return ' '.join(clean_words)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menghilangkan stopwords pada lirik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     la, la, la, la-la-la la, la-la-la, la, la-la-l...\n",
       "1     entah sudah selasa yang ke berapa masih saja k...\n",
       "2     kulepas semua yang kuinginkan tak akan kuulang...\n",
       "3     there's way time may find unknown then, loner ...\n",
       "4     georgia wrap your— want ya arms, oh, let hold ...\n",
       "5     kalau harus ku mengingatmu lagi aku takkan san...\n",
       "6     eighteen, undergrads stayed late, never made c...\n",
       "7     sandarkan lelahmu, dan ceritakan tentang apa p...\n",
       "8     kau begitu sempurna di mataku kau begitu indah...\n",
       "9     lihatlah luka ini yang sakitnya abadi yang ter...\n",
       "10    aku sedang bertanya-tanya tentang perasaan kit...\n",
       "11    saat kau jatuh lukai hati di mana pun itu i'll...\n",
       "12    malam ini aku menanti kedatanganmu mengisi sep...\n",
       "13    know want secret try hide know want don’t keep...\n",
       "14    wants beautiful goes unnoticed, knows limits c...\n",
       "Name: lirik, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lirik\"].apply(remove_stop_word_id)\n",
    "df[\"lirik\"].apply(remove_stop_word_en)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vektorisasi lirik\n",
    "```\n",
    "Vektorisasi adalah proses untuk mengubah proses mengubah setiap term menjadi bentuk vektor \n",
    "yang akan digunakan untuk digunakan sebagai fitting dalam prediksi \n",
    "machine learning\n",
    "\n",
    "Fitting adalah proses yang bertujuan membuat model beradaptasi terhadap dataset\n",
    "yang ia pakai untuk training\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer()\n",
    "vektor_lirik = tfidf_v.fit_transform(df[\"lirik\"].tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi untuk mencari lagu\n",
    "yang meliputi proses:\n",
    "```\n",
    "1. Preprocessing query (casefolding, removing stopwords)\n",
    "2. Vektorisasi query\n",
    "3. Menghitung nilai cosine similarity\n",
    "4. Mengurut nilai cosine similarity secara descending (besar -> kecil)\n",
    "5. Menampilkan GUI window yang menampilkan hasil pencarian\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cari_lagu(input_text, window):\n",
    "    query = input_text.get().lower().split(' ')\n",
    "    clean_query = \"\"\n",
    "    for i in query:\n",
    "        if i not in id_stop_factory and i not in en_stop_factory:\n",
    "            clean_query += i + \" \"\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    clean_query = clean_query.strip()\n",
    "        \n",
    "    query_vektor = tfidf_v.transform([clean_query])\n",
    "    cos_sim = cosine_similarity(query_vektor, vektor_lirik)\n",
    "    sorted_index = np.argsort(cos_sim)[0][::-1]\n",
    "    \n",
    "    global index_relevan\n",
    "    index_relevan = []\n",
    "    for i in sorted_index:\n",
    "    # Memfilter hasil dokumen yang memiliki nilai cosine similarity > 0\n",
    "        if cos_sim[0][i] > 0:\n",
    "            index_relevan.append([i, cos_sim[0][i]])\n",
    "            \n",
    "    for i in index_relevan:\n",
    "        print(\"Dokumen {} memiliki cosine similarity sebesar {:.2f}\".format(i[0], i[1]))\n",
    "        \n",
    "    print(f\"Dokumen relevan yang dihasilkan sistem yakni : {len(index_relevan)} \")\n",
    "\n",
    "    global lagu\n",
    "    lagu = []\n",
    "    for i in index_relevan:\n",
    "        x = df.iloc[i[0]]['judul']\n",
    "        y = df.iloc[i[0]]['artis']\n",
    "        z = df.iloc[i[0]]['lirik']\n",
    "        lagu.append([x, y, z])\n",
    "\n",
    "    if len(lagu) > 0:\n",
    "        target = lagu[0][0]\n",
    "    else:\n",
    "        target = \"Lagu tidak ditemukan.\"\n",
    "\n",
    "    hasil = Frame(window)\n",
    "    hasil.grid(row=0, column=0, sticky='news')\n",
    "    hasil.tkraise()\n",
    "    Label(hasil, text=\"Lagu yang anda cari adalah: \",  font=(\"Times\",20,\"bold\")).pack()\n",
    "    \n",
    "    count = 1\n",
    "    for i in lagu:\n",
    "        if count == 2:\n",
    "            Label(hasil, text=\"atau mungkin: \").pack()\n",
    "        Label(hasil, text=f\"{count}.\\t\\t{i[0]}\").pack()\n",
    "        Label(hasil, text=f\"oleh {i[1]}\").pack()\n",
    "        count += 1\n",
    "\n",
    "    Button(hasil, text=\"search again\", command=lambda:hasil.destroy()).pack()\n",
    "    Button(hasil, text=\"close\", command=lambda:window.destroy()).pack()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat GUI Window menggunakan library tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokumen 4 memiliki cosine similarity sebesar 0.22\n",
      "Dokumen 0 memiliki cosine similarity sebesar 0.01\n",
      "Dokumen 13 memiliki cosine similarity sebesar 0.01\n",
      "Dokumen 14 memiliki cosine similarity sebesar 0.01\n",
      "Dokumen relevan yang dihasilkan sistem yakni : 4 \n"
     ]
    }
   ],
   "source": [
    "window = Tk()\n",
    "input_text = StringVar()\n",
    "window.geometry(\"480x480\")\n",
    "window.title(\"Song Finder\")\n",
    "\n",
    "homepage = Frame(window)\n",
    "homepage.grid(row=0, column=0, sticky='news')\n",
    "Label(homepage, text=\"Song Finder\", bg=\"teal\", fg=\"white\").pack()\n",
    "Entry(homepage, text=\"Masukkan penggalan lirik\", textvariable=input_text).pack()\n",
    "Button(homepage, text=\"Cari\", command=lambda:cari_lagu(input_text, window)).pack()\n",
    "\n",
    "homepage.tkraise()\n",
    "window.mainloop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pendefinisian dokumen relevan (menurut ahli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dokumen_relevan_sebenarnya = {\n",
    "    'kau tetap': [1, 7, 9], \n",
    "    'all the time': [0],\n",
    "    'lost within the darkness': [4],\n",
    "    \"we're strolling down the boulevard\": [6],\n",
    "    'kau adalah hidupku' : [8]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhitungan evaluasi sistem terhadap kueri yang dimasukkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_precision_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kueri \"lost within the darkness\" memiliki nilai:\n",
      "Recall: 100 %\n",
      "Precision: 25 %\n",
      "dan Average Precision: 100 %\n"
     ]
    }
   ],
   "source": [
    "dokumen_relevan_sebenarnya_yang_dihasilkan = 0\n",
    "dokumen_ke = 0\n",
    "precision = 0\n",
    "avg_precision = 0\n",
    "sum_precision = 0\n",
    "\n",
    "for i in index_relevan:\n",
    "    dokumen_ke += 1\n",
    "    if i[0] in dokumen_relevan_sebenarnya[input_text.get()]:\n",
    "        dokumen_relevan_sebenarnya_yang_dihasilkan += 1\n",
    "        sum_precision += dokumen_relevan_sebenarnya_yang_dihasilkan/dokumen_ke\n",
    "\n",
    "if len(dokumen_relevan_sebenarnya[input_text.get()]) > 0:\n",
    "    recall = dokumen_relevan_sebenarnya_yang_dihasilkan/len(dokumen_relevan_sebenarnya[input_text.get()])\n",
    "    precision = dokumen_relevan_sebenarnya_yang_dihasilkan/len(index_relevan)\n",
    "else:\n",
    "    recall = 1\n",
    "    precision = 1\n",
    "\n",
    "avg_precision = sum_precision/len(dokumen_relevan_sebenarnya[input_text.get()])\n",
    "avg_precision_list[input_text.get()] =  avg_precision\n",
    "\n",
    "print(f\"Kueri \\\"{input_text.get()}\\\" memiliki nilai:\")\n",
    "print(f\"Recall: {int(recall*100)} %\")\n",
    "print(f\"Precision: {int(precision*100)} %\")\n",
    "print(f\"dan Average Precision: {int(avg_precision*100)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai dari Mean Avrage Precision sistem adalah : 0.7777777777777777\n"
     ]
    }
   ],
   "source": [
    "mAP = sum(avg_precision_list.values())/len(avg_precision_list)\n",
    "print(f\"Nilai dari Mean Avrage Precision sistem adalah : {mAP}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
