{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tkinter import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/revanfz/revanfz/main/dataset_lirik.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lirik\"] = df[\"lirik\"].replace(r'\\n', ' ', regex=True).str.casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menghilangkan Stopwords\n",
    "```\n",
    "Stopwords adalah kata yang tidak memiliki makna ketika berdiri sendiri\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_stop_factory = stopwords.words('indonesian')\n",
    "en_stop_factory = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_word_id(text):\n",
    "    clean_words = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word not in id_stop_factory:\n",
    "            clean_words.append(word)\n",
    "    return ' '.join(clean_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_word_en(text):\n",
    "    clean_words = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word not in en_stop_factory:\n",
    "            clean_words.append(word)\n",
    "    return ' '.join(clean_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lirik\"].apply(remove_stop_word_id)\n",
    "df[\"lirik\"].apply(remove_stop_word_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer()\n",
    "vektor_lirik = tfidf_v.fit_transform(df[\"lirik\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cari_lagu(input_text, window):\n",
    "    query = input_text.get().lower().split(' ')\n",
    "    clean_query = \"\"\n",
    "    for i in query:\n",
    "        if i not in id_stop_factory and i not in en_stop_factory:\n",
    "            clean_query += i + \" \"\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    clean_query = clean_query.strip()\n",
    "    print(clean_query)\n",
    "        \n",
    "    query_vektor = tfidf_v.transform([clean_query])\n",
    "    cos_sim = cosine_similarity(query_vektor, vektor_lirik)\n",
    "    sorted_index = np.argsort(cos_sim)[0][::-1]\n",
    "    \n",
    "    global index_relevan\n",
    "    index_relevan = []\n",
    "    for i in sorted_index:\n",
    "    # Memfilter hasil dokumen yang memiliki nilai cosine similarity > 0\n",
    "        if cos_sim[0][i] > 0:\n",
    "            index_relevan.append([i, cos_sim[0][i]])\n",
    "            \n",
    "    for i in index_relevan:\n",
    "        print(\"Dokumen {} memiliki cosine similarity sebesar {:.2f}\".format(i[0], i[1]))\n",
    "        \n",
    "    print(f\"Dokumen relevan yang dihasilkan sistem yakni : {len(index_relevan)} \")\n",
    "\n",
    "    global lagu\n",
    "    lagu = []\n",
    "    for i in index_relevan:\n",
    "        x = df.iloc[i[0]]['judul']\n",
    "        y = df.iloc[i[0]]['artis']\n",
    "        z = df.iloc[i[0]]['lirik']\n",
    "        lagu.append([x, y, z])\n",
    "\n",
    "    if len(lagu) > 0:\n",
    "        target = lagu[0][0]\n",
    "    else:\n",
    "        target = \"Lagu tidak ditemukan.\"\n",
    "\n",
    "    hasil = Frame(window)\n",
    "    hasil.grid(row=0, column=0, sticky='news')\n",
    "    hasil.tkraise()\n",
    "    Label(hasil, text=\"Lagu yang anda cari adalah: \",  font=(\"Times\",20,\"bold\")).pack()\n",
    "    \n",
    "    count = 1\n",
    "    for i in lagu:\n",
    "        if count == 2:\n",
    "            Label(hasil, text=\"atau mungkin: \").pack()\n",
    "        Label(hasil, text=f\"{count}.\\t\\t{i[0]}\").pack()\n",
    "        Label(hasil, text=f\"oleh {i[1]}\").pack()\n",
    "        count += 1\n",
    "\n",
    "    Button(hasil, text=\"search again\", command=lambda:hasil.destroy()).pack()\n",
    "    Button(hasil, text=\"close\", command=lambda:window.destroy()).pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "Dokumen 14 memiliki cosine similarity sebesar 0.03\n",
      "Dokumen 3 memiliki cosine similarity sebesar 0.03\n",
      "Dokumen 0 memiliki cosine similarity sebesar 0.02\n",
      "Dokumen relevan yang dihasilkan sistem yakni : 3 \n",
      "rinduku\n",
      "Dokumen 12 memiliki cosine similarity sebesar 0.05\n",
      "Dokumen relevan yang dihasilkan sistem yakni : 1 \n"
     ]
    }
   ],
   "source": [
    "window = Tk()\n",
    "input_text = StringVar()\n",
    "window.geometry(\"480x480\")\n",
    "window.title(\"Song Finder\")\n",
    "\n",
    "homepage = Frame(window)\n",
    "homepage.grid(row=0, column=0, sticky='news')\n",
    "Label(homepage, text=\"Song Finder\", bg=\"teal\", fg=\"white\").pack()\n",
    "Entry(homepage, text=\"Masukkan penggalan lirik\", textvariable=input_text).pack()\n",
    "Button(homepage, text=\"Cari\", command=lambda:cari_lagu(input_text, window)).pack()\n",
    "\n",
    "homepage.tkraise()\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "dokumen_relevan_sebenarnya = {'all the time': [0], 'rasa rinduku': [12]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([[0], [9, 12]])\n"
     ]
    }
   ],
   "source": [
    "print(dokumen_relevan_sebenarnya.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kueri \"rasa rinduku\" memiliki nilai:\n",
      "Recall: 100 %\n",
      "dan Precision: 100 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dokumen_relevan_sebenarnya_yang_dihasilkan = 0\n",
    "dokumen_ke = 0\n",
    "precision = 0\n",
    "for i in index_relevan:\n",
    "    if i[0] in dokumen_relevan_sebenarnya[input_text.get()]:\n",
    "        dokumen_relevan_sebenarnya_yang_dihasilkan += 1\n",
    "    dokumen_ke += 1\n",
    "    precision += dokumen_relevan_sebenarnya_yang_dihasilkan/dokumen_ke\n",
    "\n",
    "if dokumen_relevan_sebenarnya_yang_dihasilkan > 0:\n",
    "    recall = dokumen_relevan_sebenarnya_yang_dihasilkan/len(dokumen_relevan_sebenarnya[input_text.get()])\n",
    "else:\n",
    "    recall = 0  \n",
    "\n",
    "\n",
    "print(f\"Kueri \\\"{input_text.get()}\\\" memiliki nilai:\")\n",
    "print(f\"Recall: {str(recall*100).rstrip('0').rstrip('.')} %\")\n",
    "print(f\"dan Precision: {str(precision*100).rstrip('0').rstrip('.')} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
